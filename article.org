
* Глобально оптимальный, восьмой и наиболее быстрый вид интерпретаторов виртуальной машины

Дисклеймер: Эта статья вступает в полемику со статьей 2015 года за авторством Atakua, подходы из которой я и атакую. В ней Atakua исследует построение интерпретаторов байткода, но делает это без уважения. В итоге самой быстрой оказывается двоичная трансляция. Но я думаю, что он не выжал из интерпретаторов всю скорость на которую они способны, и я берусь это доказать. Более того, я рискну даже заявить что, при должном вдохновении и руководствуюясь моим методом можно написать интерпретатор байткода, который уделает JIT-компиляцию по скорости. Интересно? Читайте дальше! Но это статья не для пятничного вечера. Будет еще больше ассемблерных листингов, макросов и прочего хардкора. Вы предупреждены.

  [[img]]

Для затравки посмотрите на гистограмму. Я взял бенчмарк автора и добавил в него своих столбцов. Те что минимальной высоты - мои (кроме, разумется, нативного кода, который дан для иллюстрации пределов оптимизации). Естественно, чтобы достичь такого, мне потребовалось нарушить все правила!

Какие такие правила?

- Преждевременная оптимизация -  корень всех зол (правило Кнута)
- Оптимизируйте свою работу по оптимизации. Если не удалось уклониться от работы по оптимизации, старайтесь оптимизировать только самый горячий код. 20% горячего кода выполняются 80% времени работы программы (правило Парето)
- Не думайте, в гордыне своей, что вы умнее чем компилятор (правило Люцифера)
- Не пытайтесь оптимизировать всю программу, надорветесь (правило Фаэтона - по легенде, он попытался управлять чем-то слишком мощным и не осилил, epic fail)

  [[img]]

Давайте немного восстановим контекст. Вот картинка из статьи Atakua, которая все объясняет (если нет - то стоит освежить в памяти [[его статью]])

Я начал с его tailrecursive-варианта и стал вносить в него усовершенствования. Напомню, что этот вариант демонстрирует у автора лучшую скорость, потому что каждая из service_routune, интерпретирующая инструкцию в своем конце содержит инлайненный код для операций по интерпретации следующего байткода advance_pc,fetch_decode, и наконец, dispatch. Этот dispatch и выполняет хвостовой вызов.

Почему это так быстро? Потому что процессорный предсказатель ветвлений ассоциирует с каждым переходом историю предыдущих переходов, благодаря чему для каждого перехода появляется какая-никая история, улучшающая предсказания. А так как в последовательности команд байткода есть какая-то логика (например за сравнением обычно следует переход) то у каждого хвостового dispatch есть обоснованные предположения о том, в какую следующую команду ему нужно будет прыгнуть - и это еще до того как этот прыжок начнет выполняться. Поэтому процессор начинает выполнять следующую команду заранее, предполагая отбросить результаты выполнения, если произойдет misprediction.

Какие логичные выводы мы можем сделать из этого? Ну, во-первых, можно, предположить, что будет лучше, если в начале любой предсказанной команды будет поменьше ветвлений. Так как ресурсы предсказателя не бесконечны и на несколько ветвлений вперед ему заглядывать сложнее. Поэтому, например, при кодировании стековых операций (которые, очевидно, самые частые в нашей стековой виртуальной машине), возможно стоит сначала выполнить стековую операцию (PUSH или POP) а потом проверить не вышла ли она за границы. Выход за границы - редкое явление и оно в любом случае приводит к завершению работы, поэтому мы ничего не теряем. Возьмем это на заметку.

Также избегать лишних ветвлений помогает CMOV, но оптимизации с его использованием выходят за рамки этой статьи.

Atakua проделал отличную работу, подведя к реализации tailrecursive виртуальной машины, для чего, конечно же надо было рассмотреть все предыдущие варианты, и теперь мы можем продвигаться дальше. Пришло время нарушать правила!

Начнем с последнего правила и попытаемся глобально оптимизировать всю программу: наша задача хорошо подходит для этого, потому что сама программа, т.е. интерпретатор байтода - очень компактна. Кроме того, тут мы можем побить компилятор, оптимизации которого в большей степени локальны. Глобальный анализ потребовал бы анализа слишком многих путей выполнения. Но в нашей виртуальной машине пути выполнения нам понятны - сервисные процедуры вызывают одна другую до тех пор, пока не будет выполнена инструкция HALT. Потом процессор переключится в другое состояние и больше не будет выполнять инструкции.

Взглянем на структуры данных, которые управляют состоянием процессора и интерпретатором байткода в целом:

#+BEGIN_SRC c
/* Simulated processor state */
typedef struct {
    uint32_t pc; /* Program Counter */
    int32_t sp;  /* Stack Pointer */
    cpu_state_t state;
    uint64_t steps; /* Statistics - total number of instructions */
    uint32_t stack[STACK_CAPACITY]; /* Data Stack */
    const Instr_t *pmem;            /* Program Memory */
} cpu_t;

/* A struct to store information about a decoded instruction */
typedef struct {
    Instr_t opcode;
    int length; /* size of instruction, zero for branches */
    int32_t immediate; /* argument of opcode if exists */
} decode_t;
#+END_SRC

О, а их не так уж и много! Что если мы перенесем их в регистры? Тогда наша виртуальная машина в процессе своей работы сможет вообще не трогать память - кроме стека - и это хороший задел для начала:

#+BEGIN_SRC asm
  #define pc              %r9
  #define sp              %rsp
  #define state           %r15
  #define steps           %r8
  #define prog_mem        %rsi

  #define opcode          %edx
  #define opcode_full     %rdx
  #define immediate       %r14d
  #define immediate_full  %r14
#+END_SRC

Тут следует сказать про то, как мы можем оптимизировать работу со стеком. В оригинальной виртуальной машине Atakua стек 32-разрядный и содержит 32 значения. Это то с чем приходится иметь дело, т.к. если поменять это то сравнительный бенчмарк станет нерелевантным. Но при реализации такого стека "в лоб" пришлось бы иметь дело с массивом uint32_t, доступ к которому будет выполняться с помощью комбинации базового адреса и смещения. Это куда менее оптимально, чем использовать стек хозяской машины, хотя он и 64-разрядный. Верхние 32 бита будут заняты нулями, но зато со стеком будут работать высокооптимизированные инструкции процессора, предназначенные для стека. И мы сэкономим один регистр, потому что у нас нет базового адреса.

Но есть кое-что другое важное для стека - границы. Поскольку они проверяются при каждой операции со стеком, мы тем более должны положить их в регистры. По этой же причине нам понадобится 32-разрядная часть 64-разрядного регистра для некоторых переменных.

#+BEGIN_SRC asm
  #define stack_max       %rbp
  #define stack_min       %rbx
#+END_SRC

Что еще мы можем положить в регистры, чтобы поменьше задействовать память? Только две вещи остались, первая - это ограничение на количество шагов которое может сделать интерпретатор, а вторая - это базовый адрес массива с процедурами, каждая из которых обслуживает свой опкод виртуальной машины.

#+BEGIN_SRC asm
  #define steplimit       %rcx
  #define routines        %rdi
#+END_SRC

Отлично! Мы разместили все переменные в регистрах и у нас даже остались лишние регистры. Два из них стоит занять под часто используемые константы:

#+BEGIN_SRC asm
  # 1 = Cpu_Halted
  #define one             %r11
  # 2 = Cpu_Break
  #define two             %r12
#+END_SRC

И еще остается два регистра, которые можно использовать чтобы кэшировать два верхних элемента стека. Эта техника используется при реализации некторых фортов.


...

Автор считает что полагаться следует только на бенчмарки - "верить нельзя никому". Ответственно заявляю: Пока еще можно! Верить бенчмаркам недостойно и малодушно для специалиста по низкоуровневой оптимизации! Он должен верить только той модели работы машины (на всех уровнях), которая есть в его голове! Ведь именно из этой модели возникают гипотезы для оптимизаций. Такую модель стоит беречь как самое ценное содержимое головы. Но если бенчмарк не согласуется с моделью, возможно, следуюет разобраться - почему. И (иногда) уточнить модель. Хотя, возможно и не стоит - "Один вводящий в заблуждение бенчмарк может за одну минуту достичь того, что невозможно получить за годы хорошей инженерной работы." (с) Dilbert.

...

- Ну, отпуск закончился, пора и на работу
