
* Глобально оптимальный, восьмой и наиболее быстрый вид интерпретаторов виртуальной машины

** Приключения начинаются

Совершать невозможное и раздавать пинки здравому смыслу — в этом и состоит жизнь членов Гуррен-Дана! (C) Камина

Дисклеймер: Эта статья вступает в полемику со статьей 2015 года за авторством Atakua, подходы из которой я и атакую. Atakua исследует построение интерпретаторов байткода, но делает это без уважения - быстрейшей оказывается двоичная трансляция. Но я думаю, что он не выжал из интерпретаторов всю скорость на которую они способны. И в этой статье я попытаюсь это доказать. Я даже рискну сказать, что, руководствуюясь этим методом, можно написать интерпретатор байткода, который уделает JIT-компиляцию по скорости. Интересно? Читайте дальше! Но это статья не для пятничного вечера. Будет еще больше ассемблерных листингов, макросов и прочего хардкора. И ни одной сгенерированной нейросетью картинки.

  [[img]]

Для затравки посмотрите на гистограмму. Я использую бенчмарк автора, добавляя в него свои результаты. Самый маленький столбец, это нативный код, данный Atakua в качестве оценки пределов оптимизации). Мои достижения отмечены цветом.

Чтобы достичь такого, потребуется нарушать правила. Какие?

- Преждевременная оптимизация -  корень всех зол (правило Кнута)
- Оптимизируйте свою работу по оптимизации. Если не удалось уклониться от работы по оптимизации, старайтесь оптимизировать только самый горячий код. 20% горячего кода выполняются 80% времени работы программы (правило Парето)
- Не считайте себя умнее разрабочиков компилятора (правило Люцифера)
- Оптимизируйте локально, выбирайте самый нагруженный код. Не пытайтесь оптимизировать всю программу (правило Фаэтона - по легенде, он попытался управлять тем, что ему не по плечу, и поплатился)

  [[img]]

Давайте немного восстановим контекст. Вот картинка из статьи Atakua, которая все объясняет (если нет - то стоит освежить в памяти [[его статью]])

Я начал с его tailrecursive-варианта и стал вносить в него усовершенствования. Напомню, что этот вариант демонстрирует у автора лучшую скорость. Почему? Потому что каждая из service_routune, в своем конце содержит инлайненный код для операций по интерпретации: ADVANCE_PC,FETCH_DECODE, и наконец, DISPATCH. Этот DISPATCH и выполняет хвостовой вызов.

Почему это так быстро? Потому что процессорный предсказатель ветвлений ассоциирует с каждым переходом историю предыдущих переходов. Благодаря этому для каждого перехода появляется какая-никая история, улучшающая предсказания. А раз в последовательности команд байткода есть какая-то логика (например за сравнением обычно следует переход), то у каждого хвостового DISPATCH есть предположения о том, в какую следующую команду ему нужно будет прыгнуть. Эти предположения есть еще до того как этот прыжок начнет выполняться. Поэтому процессор начинает выполнять следующую команду заранее, ну а если произойдет misprediction можно просто отбросить результаты выполнения.

Atakua проделал отличную работу, подведя к реализации tailrecursive виртуальной машины, для чего, конечно же, надо было рассмотреть все предыдущие варианты (они тоже интересные), и теперь мы можем продвигаться дальше. Пришло время нарушать правила!

Начнем с последнего правила и попытаемся глобально оптимизировать всю программу: наша задача хорошо подходит для этого, потому что сама программа, интерпретатор байтода - компактна.

Кроме того, тут мы как раз и можем побить компилятор, оптимизации которого в большей степени локальны. Глобальный анализ потребовал бы от компилятора анализа слишком многих путей выполнения. Но в нашей виртуальной машине все пути выполнения нам понятны - сервисные процедуры вызывают одна другую до тех пор, пока не будет выполнена инструкция HALT. Потом виртуальный процессор больше не будет выполнять инструкции.

Взглянем на структуры данных, которые управляют состоянием процессора и интерпретатором байткода в целом:

#+BEGIN_SRC c
  /* Simulated processor state */
  typedef struct {
      int32_t sp;  /* Stack Pointer */
      uint64_t steps; /* Statistics - total number of instructions */
      uint32_t stack[STACK_CAPACITY]; /* Data Stack */
      uint32_t pc; /* Program Counter */
      const Instr_t *pmem;            /* Program Memory */
      cpu_state_t state;
  } cpu_t;

  /* A struct to store information about a decoded instruction */
  typedef struct {
      Instr_t opcode;
      int length; /* size of instruction, zero for branches */
      int32_t immediate; /* argument of opcode if exists */
  } decode_t;
#+END_SRC

О, а их не так уж и много! Что если мы перенесем их в регистры? Тогда наша виртуальная машина в процессе своей работы сможет вообще не трогать память - кроме стека - и это хороший задел для начала:

#+BEGIN_SRC asm
  #define sp              %rsp
  #define steps           %r8
  #define pc              %r9
  #define prog_mem        %rsi
  #define state           %r15

  #define opcode64        %rdx
  #define opcode32        %edx
  #define immed64         %r14
  #define immed32         %r14d

#+END_SRC

Тут следует сказать про то, как мы можем оптимизировать работу со стеком. В оригинальной виртуальной машине Atakua стек 32-разрядный и содержит 32 значения. Это то с чем приходится иметь дело, если сделать иначе, то сравнительный бенчмарк станет нерелевантным. Но при реализации такого стека "в лоб" пришлось бы иметь дело с массивом uint32_t, доступ к которому будет выполняться с помощью комбинации базового адреса и смещения. Это куда менее оптимально, чем использовать стек хозяйской машины, хотя он и 64-разрядный. Верхние 32 бита будут заняты нулями, но зато со стеком будут работать инструкции процессора, предназначенные для стека. И мы сэкономим один регистр для базового адреса.

Но есть кое-что другое важное для стека - границы. Поскольку они проверяются при каждой операции со стеком, мы тем более должны положить их в регистры.

#+BEGIN_SRC asm
  /* Удобно запомнить, если воспринимать "b" как "border" */
  #define stack_max       %rbp
  #define stack_min       %rbx
#+END_SRC

Что еще частоиспользуемого можно положить в регистры, чтобы поменьше задействовать память? Остались две вещи: первая - это ограничение на количество шагов которое может сделать интерпретатор, а вторая - это базовый адрес массива указателей на процедуры. Каждая из них обслуживает свой опкод виртуальной машины.

#+BEGIN_SRC asm
  #define steplimit       %rcx
  #define routines        %rdi
#+END_SRC

Отлично! Мы разместили все переменные в регистрах и у нас даже остались лишние регистры. Два из них стоит занять под часто используемые константы:

#+BEGIN_SRC asm
  # 1 = Cpu_Halted
  #define one             %r11
  # 2 = Cpu_Break
  #define two             %r12
#+END_SRC

И еще остается два регистра, которые можно использовать чтобы кэшировать два верхних элемента стека. Это используется при реализации фортов и помогает улучшить производительность часто выполняемых SWAP и OVER. Несколько позже я покажу эту технику в деталях.

#+BEGIN_SRC asm
  #define top             %rax
  #define subtop          %r10
#+END_SRC

Обратите внимания на выбор %rax в качестве регистра, который кэширует вершину стека. Некоторые опкоды, такие как DIV, используют %rax в качестве неявного операнда, и если мы уже имеем операнд на вершине стека, его не придется загружать, что сэкономит нам одну команду ассемблера в реализации MOD далее.

Итак, мы заняли все регистры, кроме одного. Назовем его "аккумулятор" и будем использовать в случае острой необходимости:

#+BEGIN_SRC asm
  # define acc            %r13
#+END_SRC

** Ма, смотри, я могу без рук

То, всё-таки, приверженец идейный
   Едва ли убоится божества,
Едва ли убеждения оставит:
   Скорее уж, машина неправа.

А, впрочем... в памяти машины
   Вручную догмы прописать
Ещё возможно. И несложно.
   Вот только бы компьютер не сломать...

"Но подождите!" - скажет мимокрокодил со смузи в одной руке и компилятором в другой, - "Разве мы можем вручную распределить все регистры, не оставив ни одного компилятору? Даже Atakua в своей статье прибил только одну переменную к регистру %r15!

Ну говорить, что настоящие хакеры (в отличии от неопытных студентов) не используют компилятор (для написания оптимизированных виртуальных машин), хм.. не в духе времени: "можно нехило согреться" (с)🔥 Лучше сказать, что рекомендация компилятору привязать одну глобальную переменную к регистру - это всего-лишь рекомендация (за это не наказывают) и компилятор может ее проигнорировать. Но вот рекомендация прибить все регистры - это уже троллинг. Поэтому пора расчехлить ассемблер, и конечно мы будем использовать ассемблер, предназначенный служить бакендом GCC, а не для того чтобы на нем писал человек, настолько взрывоопасный, что это даже отразили в его названии: GAS.

И на третий день Бог создал "Ремингтон" со скользящим затвором, чтобы человек стрелял в динозавров и прикладных программистов... Аминь! (с) почти дословно.

Итак, каждая сервисная процедура у Atakua заканчивается следующей последовательностью:

#+BEGIN_SRC c
  ADVANCE_PC();
  ,*pdecoded = fetch_decode(pcpu);
  DISPATCH();
#+END_SRC

...поэтому этот код повторяется чуть менее чем везде и представляет собой отличного кандидата для оптимизации. Что же в нем происходит?

#+BEGIN_SRC c
  #define DISPATCH() service_routines[pdecoded->opcode](pcpu, pdecoded);

  #define ADVANCE_PC() do {               \
    pcpu->pc += pdecoded->length;         \
    pcpu->steps++;                        \
    if (pcpu->state != Cpu_Running        \
          || pcpu->steps >= steplimit)    \
       return;                            \
    } while(0);

  static inline decode_t fetch_decode(cpu_t *pcpu) {
    return decode(fetch_checked(pcpu), pcpu);
  }
#+END_SRC

Decode помещает текущую инструкцию в переменную opcode и вычисляет её длину. Если инструкция имеет непосредственный операнд, который следует за ней, то он помещается в переменную immediate. fetch_checked проверят не вышел ли program_counter за пределы байткода программы:

#+BEGIN_SRC c
  static inline Instr_t fetch_checked(cpu_t *pcpu) {
      if (!(pcpu->pc < PROGRAM_SIZE)) {
          printf("PC out of bounds\n");
          pcpu->state = Cpu_Break;
          return Instr_Break;
      }
      return fetch(pcpu);
  }
#+END_SRC

Пожалуй я лучше не буду показывать вам, во что превращает этот код компилятор (нас могут читать дети!): даже на высоких уровнях оптимизации на это без слез не взглянешь. Многие сейчас говорят, что компиляторы теперь гораздо лучше в оптимизации, чем человек. Но я подозреваю, что это потому, что пока средний компилятор умнел, тот человек, с которым он соревновался, занимался неизвестно чем. Что и говорить, если в наши дни некоторые разработчики виртуальных машин даже позволяют себе иметь семью!

Итак, мы можем лучше:

#+BEGIN_SRC asm
  .macro FETCH_DECODE
      FETCH_CHECKED
      DECODE
  .endm
#+END_SRC

Эти двое всегда ходят парой.

#+BEGIN_SRC asm
  .macro FETCH_CHECKED
      .if MAX_PROGRAM_SIZE_CHECK
        movq    $512, opcode64   # (opcode64 := max_program_size)
        cmp     pc, opcode64
        jb      handle_pc_out_of_bound  # (pc > max_program_size)
      .endif
      FETCH
  .endm
#+END_SRC

Проверка на выход за пределы 512-слов памяти программы сделана отключаемой с помощью переменной времени компиляции, чтобы можно было оценить, насколько она замедляет выполнение. Если она сработала, интерпретатор байткода печатает сообщение и выходит, как и в остальных случаях обработки ошибок.

#+BEGIN_SRC asm
  .macro FETCH
      mov     (prog_mem, pc, 4), opcode32     # prog_mem[pc]
  .endm

  .macro DECODE
      mov     4(prog_mem, pc, 4), immed32     # prog_mem[pc+1]
  .endm
#+END_SRC

opcode32 потому что мы используем только младшую половину регистра, старшая заполнена нулями - мы имеем дело с 32-битной виртуальной машиной на 64-разрядной хозяйской системе.

Технически мы видим здесь два чтения из памяти. Можно было бы прочесть одно 64-разрядное слово, и применить сдвиги и перемещение, чтобы получить нужную половину, но на это уходит больше времени, чем удается выиграть.

#+BEGIN_SRC asm


#+END_SRC

...

Автор считает что полагаться следует только на бенчмарки - "верить нельзя никому". Ответственно заявляю: Пока еще можно! Верить бенчмаркам недостойно и малодушно для специалиста по низкоуровневой оптимизации! Он должен верить только той модели работы машины (на всех уровнях), которая есть в его голове! Ведь именно из этой модели возникают гипотезы для оптимизаций. Такую модель стоит беречь как самое ценное содержимое головы. Но если бенчмарк не согласуется с моделью, возможно, следуюет разобраться - почему. И (иногда) уточнить модель. Хотя, возможно и не стоит - "Один вводящий в заблуждение бенчмарк может за одну минуту достичь того, что невозможно получить за годы хорошей инженерной работы." (с) Dilbert.

...

- Ну, отпуск закончился, пора и на работу
