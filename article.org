
* Глобально оптимальный, восьмой и наиболее быстрый вид интерпретаторов виртуальной машины

Дисклеймер: Эта статья вступает в полемику со статьей 2015 года за авторством Atakua, подходы из которой я и атакую. Atakua исследует построение интерпретаторов байткода, но делает это без уважения - быстрейшей оказывается двоичная трансляция. Но я думаю, что он не выжал из интерпретаторов всю скорость на которую они способны. И в этой статье я попытаюсь это доказать. Я даже рискну сказать, что, руководствуюясь этим методом, можно написать интерпретатор байткода, который уделает JIT-компиляцию по скорости. Интересно? Читайте дальше! Но это статья не для пятничного вечера. Будет еще больше ассемблерных листингов, макросов и прочего хардкора.

  [[img]]

Для затравки посмотрите на гистограмму. Я использую бенчмарк автора, добавляя в него свои результаты. Самый маленький столбец, это нативный код, данный Atakua в качестве оценки пределов оптимизации). Мои достижения отмечены цветом.

Чтобы достичь такого, потребуется нарушать правила. Какие?

- Преждевременная оптимизация -  корень всех зол (правило Кнута)
- Оптимизируйте свою работу по оптимизации. Если не удалось уклониться от работы по оптимизации, старайтесь оптимизировать только самый горячий код. 20% горячего кода выполняются 80% времени работы программы (правило Парето)
- Не считайте себя умнее разрабочиков компилятора (правило Люцифера)
- Оптимизируйте локально, выбирайте самый нагруженный код. Не пытайтесь оптимизировать всю программу (правило Фаэтона - по легенде, он попытался управлять тем, что ему не по плечу, и поплатился)

  [[img]]

Давайте немного восстановим контекст. Вот картинка из статьи Atakua, которая все объясняет (если нет - то стоит освежить в памяти [[его статью]])

Я начал с его tailrecursive-варианта и стал вносить в него усовершенствования. Напомню, что этот вариант демонстрирует у автора лучшую скорость. Почему? Потому что каждая из service_routune, в своем конце содержит инлайненный код для операций по интерпретации: ADVANCE_PC,FETCH_DECODE, и наконец, DISPATCH. Этот DISPATCH и выполняет хвостовой вызов.

Почему это так быстро? Потому что процессорный предсказатель ветвлений ассоциирует с каждым переходом историю предыдущих переходов. Благодаря этому для каждого перехода появляется какая-никая история, улучшающая предсказания. А раз в последовательности команд байткода есть какая-то логика (например за сравнением обычно следует переход), то у каждого хвостового DISPATCH есть предположения о том, в какую следующую команду ему нужно будет прыгнуть. Эти предположения есть еще до того как этот прыжок начнет выполняться. Поэтому процессор начинает выполнять следующую команду заранее, ну а если произойдет misprediction можно просто отбросить результаты выполнения.

Atakua проделал отличную работу, подведя к реализации tailrecursive виртуальной машины, для чего, конечно же, надо было рассмотреть все предыдущие варианты (они тоже интересные), и теперь мы можем продвигаться дальше. Пришло время нарушать правила!

Начнем с последнего правила и попытаемся глобально оптимизировать всю программу: наша задача хорошо подходит для этого, потому что сама программа, интерпретатор байтода - компактна.

Кроме того, тут мы как раз и можем побить компилятор, оптимизации которого в большей степени локальны. Глобальный анализ потребовал бы от компилятора анализа слишком многих путей выполнения. Но в нашей виртуальной машине все пути выполнения нам понятны - сервисные процедуры вызывают одна другую до тех пор, пока не будет выполнена инструкция HALT. Потом виртуальный процессор больше не будет выполнять инструкции.

Взглянем на структуры данных, которые управляют состоянием процессора и интерпретатором байткода в целом:

#+BEGIN_SRC c
  /* Simulated processor state */
  typedef struct {
      int32_t sp;  /* Stack Pointer */
      uint64_t steps; /* Statistics - total number of instructions */
      uint32_t stack[STACK_CAPACITY]; /* Data Stack */
      uint32_t pc; /* Program Counter */
      const Instr_t *pmem;            /* Program Memory */
      cpu_state_t state;
  } cpu_t;

  /* A struct to store information about a decoded instruction */
  typedef struct {
      Instr_t opcode;
      int length; /* size of instruction, zero for branches */
      int32_t immediate; /* argument of opcode if exists */
  } decode_t;
#+END_SRC

О, а их не так уж и много! Что если мы перенесем их в регистры? Тогда наша виртуальная машина в процессе своей работы сможет вообще не трогать память - кроме стека - и это хороший задел для начала:

#+BEGIN_SRC asm
  #define sp              %rsp
  #define steps           %r8
  #define pc              %r9
  #define prog_mem        %rsi
  #define state           %r15

  #define opcode          %edx
  #define opcode_full     %rdx
  #define immediate       %r14d
  #define immediate_full  %r14
#+END_SRC

Тут следует сказать про то, как мы можем оптимизировать работу со стеком. В оригинальной виртуальной машине Atakua стек 32-разрядный и содержит 32 значения. Это то с чем приходится иметь дело, если сделать иначе, то сравнительный бенчмарк станет нерелевантным. Но при реализации такого стека "в лоб" пришлось бы иметь дело с массивом uint32_t, доступ к которому будет выполняться с помощью комбинации базового адреса и смещения. Это куда менее оптимально, чем использовать стек хозяйской машины, хотя он и 64-разрядный. Верхние 32 бита будут заняты нулями, но зато со стеком будут работать инструкции процессора, предназначенные для стека. И мы сэкономим один регистр для базового адреса.

Но есть кое-что другое важное для стека - границы. Поскольку они проверяются при каждой операции со стеком, мы тем более должны положить их в регистры.

#+BEGIN_SRC asm
  /* Удобно запомнить, если воспринимать "b" как "border" */
  #define stack_max       %rbp
  #define stack_min       %rbx
#+END_SRC

Что еще частоиспользуемого можно положить в регистры, чтобы поменьше задействовать память? Остались две вещи: первая - это ограничение на количество шагов которое может сделать интерпретатор, а вторая - это базовый адрес массива указателей на процедуры. Каждая из них обслуживает свой опкод виртуальной машины.

#+BEGIN_SRC asm
  #define steplimit       %rcx
  #define routines        %rdi
#+END_SRC

Отлично! Мы разместили все переменные в регистрах и у нас даже остались лишние регистры. Два из них стоит занять под часто используемые константы:

#+BEGIN_SRC asm
  # 1 = Cpu_Halted
  #define one             %r11
  # 2 = Cpu_Break
  #define two             %r12
#+END_SRC

И еще остается два регистра, которые можно использовать чтобы кэшировать два верхних элемента стека. Это используется при реализации фортов и помогает улучшить производительность часто выполняемых SWAP и OVER. Несколько позже я покажу эту технику в деталях.

#+BEGIN_SRC asm
  #define top             %rax
  #define subtop          %r10
#+END_SRC

Обратите внимания на выбор %rax в качестве регистра, который кэширует вершину стека. Некоторые опкоды, такие как DIV, используют %rax в качестве неявного операнда, и если мы уже имеем операнд на вершине стека, его не придется загружать, что сэкономит нам одну команду ассемблера в реализации MOD далее.

Итак, мы заняли все регистры, кроме одного, назовем его "аккумулятор" и будем использовать в случае острой необходимости:

#+BEGIN_SRC asm
  # define acc            %r13
#+END_SRC


...

Автор считает что полагаться следует только на бенчмарки - "верить нельзя никому". Ответственно заявляю: Пока еще можно! Верить бенчмаркам недостойно и малодушно для специалиста по низкоуровневой оптимизации! Он должен верить только той модели работы машины (на всех уровнях), которая есть в его голове! Ведь именно из этой модели возникают гипотезы для оптимизаций. Такую модель стоит беречь как самое ценное содержимое головы. Но если бенчмарк не согласуется с моделью, возможно, следуюет разобраться - почему. И (иногда) уточнить модель. Хотя, возможно и не стоит - "Один вводящий в заблуждение бенчмарк может за одну минуту достичь того, что невозможно получить за годы хорошей инженерной работы." (с) Dilbert.

...

- Ну, отпуск закончился, пора и на работу
